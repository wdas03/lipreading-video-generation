{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-09T04:26:08.641585Z","iopub.status.busy":"2024-04-09T04:26:08.640995Z","iopub.status.idle":"2024-04-09T04:26:08.646456Z","shell.execute_reply":"2024-04-09T04:26:08.645475Z","shell.execute_reply.started":"2024-04-09T04:26:08.641554Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","\n","import os\n","from tqdm import tqdm\n","from copy import deepcopy\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:10.627951Z","iopub.status.busy":"2024-04-09T04:26:10.627576Z","iopub.status.idle":"2024-04-09T04:26:10.632047Z","shell.execute_reply":"2024-04-09T04:26:10.631197Z","shell.execute_reply.started":"2024-04-09T04:26:10.627923Z"},"trusted":true},"outputs":[],"source":["import sys"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:11.994453Z","iopub.status.busy":"2024-04-09T04:26:11.994113Z","iopub.status.idle":"2024-04-09T04:26:12.004405Z","shell.execute_reply":"2024-04-09T04:26:12.004136Z","shell.execute_reply.started":"2024-04-09T04:26:11.994425Z"},"trusted":true},"outputs":[],"source":["with open('output.txt', 'w') as f:\n","    # Redirect stdout to the file\n","    sys.stdout = f\n","    sys.stderr = f\n","    \n","    for i in tqdm(range(5)):\n","        pass\n","# Restore stdout to default\n","sys.stdout = sys.__stdout__\n","sys.stderr = sys.__stderr__"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:12.439858Z","iopub.status.busy":"2024-04-09T04:26:12.439058Z","iopub.status.idle":"2024-04-09T04:26:12.443447Z","shell.execute_reply":"2024-04-09T04:26:12.443122Z","shell.execute_reply.started":"2024-04-09T04:26:12.439816Z"},"trusted":true},"outputs":[],"source":["def get_files(folder='/kaggle/input/lrs-pta/mvlrs_v1/pretrain'):\n","    files = {'.mp4': [], '.txt': []}\n","    for dirname, _, filenames in os.walk(folder):\n","        for filename in filenames:\n","            if len(files['.mp4']) > 1500:\n","                return files\n","            files[filename[-4:]].append(os.path.join(dirname, filename))\n","    return files"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:12.834084Z","iopub.status.busy":"2024-04-09T04:26:12.833681Z","iopub.status.idle":"2024-04-09T04:26:12.837792Z","shell.execute_reply":"2024-04-09T04:26:12.837361Z","shell.execute_reply.started":"2024-04-09T04:26:12.834050Z"},"trusted":true},"outputs":[],"source":["def get_timestamps(filename):\n","    file = open(filename)\n","    text_data = file.readlines()[4:]\n","    timestamps = {}\n","    for line in text_data:\n","        line = line.split()\n","        timestamps[(float(line[1]), float(line[2]))] = line[0]\n","    return timestamps"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:13.160114Z","iopub.status.busy":"2024-04-09T04:26:13.159534Z","iopub.status.idle":"2024-04-09T04:26:13.173098Z","shell.execute_reply":"2024-04-09T04:26:13.172827Z","shell.execute_reply.started":"2024-04-09T04:26:13.160081Z"},"trusted":true},"outputs":[],"source":["def get_frames(filename, timestamps):\n","    vid = cv2.VideoCapture(filename)\n","    fps = vid.get(cv2.CAP_PROP_FPS)\n","\n","    data = []\n","    check = True\n","    i = 0\n","    \n","    top_crop = 0.2\n","    bottom_crop = 0.2\n","    left_crop = 0.2\n","    right_crop = 0.2\n","    \n","#     face_cascade = cv2.CascadeClassifier('/kaggle/input/haarcascade-frontalface-default-xml/haarcascade_frontalface_default.xml')\n","    mouth_cascade = cv2.CascadeClassifier('./haarcascade_mcs_mouth.xml')\n","    ds_factor = 0.5\n","    \n","    skipped_frames = []\n","    skipped_flag = None\n","\n","    while check:\n","        check, arr = vid.read()\n","        if check and not i % 1:  # This line is to subsample (i.e. keep one frame every 5)\n","            height, width, _ = arr.shape\n","#             data.append(arr[round(height*top_crop):round(height*(1-bottom_crop)), round(width*left_crop):round(width*(1-right_crop))])  \n","            \n","#             frame = cv2.resize(arr, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n","#             gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","#             mouth_rects = mouth_cascade.detectMultiScale(gray, 1.05, 8)\n","#             for (x,y,w,h) in mouth_rects:\n","#                 y = int(y - 0.15*h)\n","#                 cv2.rectangle(arr, (x,y), (x+w,y+h), (0,255,0), 1)\n","#                 data.append(arr[y:y+h, x:x+w])\n","#                 data.append(arr)\n","            arr = arr[int(height*0.3):,:,:]\n","            gray = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY) \n","  \n","#             faces = face_cascade.detectMultiScale(gray, 1.05, minNeighbors=1, minSize=(60,60)) \n","            \n","#             k = 1.4\n","#             for (x,y,w,h) in faces: \n","#                 w1 = int(w * k)\n","#                 h1 = int(h * k)\n","#                 cv2.rectangle(arr,(x,y),(x+w1,y+h1),(255,255,0),1)  \n","#                 roi_gray = gray[y:y+h1, x:x+w1] \n","#                 roi_color = arr[y:y+h1, x:x+w1] \n","\n","#                 mouths = mouth_cascade.detectMultiScale(roi_gray, 1.05, minNeighbors=4)\n","                \n","#                 lowest = (0,0,0,0)\n","#                 for (mx,my,mw,mh) in mouths:\n","#                     if my > lowest[1]:\n","#                         lowest = (mx,my,mw,mh)\n","#                 cv2.rectangle(roi_color,(int(lowest[0] - min(5, lowest[2]*0.25)),int(lowest[1] - min(5, lowest[1]*0.05))),\n","#                               (int(lowest[0]+min(lowest[2]+5, lowest[2]*1.25)),int(lowest[1]+min(lowest[3]+5, lowest[3]*1.05))),\n","#                               (0,127,255),1)\n","                \n","\n","#                 for (mx,my,mw,mh) in mouths: \n","#                     cv2.rectangle(roi_color,(mx,my),(mx+mw,my+mh),(0,127,255),1)\n","#                     break\n","#                 break\n","            \n","#             if len(faces) == 0:\n","#                 mouths = mouth_cascade.detectMultiScale(gray, 1.01, minNeighbors=4)\n","#                 lowest = (0,0,0,0)\n","#                 for (mx,my,mw,mh) in mouths:\n","#                     if my > lowest[1]:\n","#                         lowest = (mx,my,mw,mh)\n","#                 cv2.rectangle(arr,(int(lowest[0] - min(5, lowest[2]*0.25)),int(lowest[1] - min(5, lowest[1]*0.05))),\n","#                               (int(lowest[0]+min(lowest[2]+5, lowest[2]*1.25)),int(lowest[1]+min(lowest[3]+5, lowest[3]*1.05))),\n","#                               (0,127,255),1)\n","\n","            mouths = mouth_cascade.detectMultiScale(gray, 1.01, minNeighbors=4)\n","            dist_to_center = height\n","            x, y, w, h = (0, 0, 0, 0)\n","            for (mx,my,mw,mh) in mouths:\n","                if abs(my-(height//2 - int(height*0.3))) < dist_to_center:\n","                    x, y, w, h = mx, my, mw, mh\n","                    dist_to_center = abs(my-(height//2 - int(height*0.3)))\n","            \n","            temp_arr = deepcopy(arr)\n","            #arr = arr[y:y+h,x:x+w,:]\n","            try:\n","                arr = cv2.resize(arr, dsize=(48, 32), interpolation=cv2.INTER_CUBIC)\n","                data.append(arr)\n","            except:\n","                # skipped_frames.append(i)\n","                # data.append(None)\n","                return None\n","                # skipped_flat = True\n","                #plt.imshow(temp_arr)\n","                #plt.show()\n","                continue\n","        i += 1\n","\n","#     data = np.array(data)\n","    \n","    frames = {}\n","    \n","    for start, end in timestamps:\n","        start_frame = round(fps * start)\n","        end_frame = round(fps * end)\n","        \n","        frames[(start,end)] = data[start_frame:end_frame+1]\n","    \n","    return frames"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:13.385383Z","iopub.status.busy":"2024-04-09T04:26:13.384667Z","iopub.status.idle":"2024-04-09T04:26:13.388039Z","shell.execute_reply":"2024-04-09T04:26:13.387799Z","shell.execute_reply.started":"2024-04-09T04:26:13.385355Z"},"trusted":true},"outputs":[],"source":["f = open('real_model_output.txt', 'w')\n","# Redirect stdout to the file\n","sys.stdout = f\n","sys.stderr = f\n","\n","# Restore stdout to default\n","# sys.stdout = sys.__stdout__\n","# sys.stderr = sys.__stderr__"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T04:26:13.652020Z","iopub.status.busy":"2024-04-09T04:26:13.651726Z"},"trusted":true},"outputs":[],"source":["files = get_files()\n","timestamps = {}\n","frames = {}\n","for file in tqdm(files['.txt'][:1000]):\n","    prefix = file[:-4]\n","    temp_timestamps = get_timestamps(file)\n","    temp_frame = get_frames(prefix + '.mp4', temp_timestamps)\n","    if temp_frame!= None:\n","        frames[prefix] = temp_frame\n","        timestamps[prefix] = temp_timestamps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T05:27:32.872614Z","iopub.status.busy":"2024-03-04T05:27:32.872217Z","iopub.status.idle":"2024-03-04T05:27:38.252417Z","shell.execute_reply":"2024-03-04T05:27:38.251548Z","shell.execute_reply.started":"2024-03-04T05:27:32.872585Z"},"trusted":true},"outputs":[],"source":["# with open('optical_flow_outputs.pkl', 'wb') as file:\n","#     pickle.dump(optical_flow_outputs, file)\n","    \n","with open('frames.pkl', 'wb') as file:\n","    pickle.dump(frames, file)\n","    \n","with open('timestamps.pkl', 'wb') as file:\n","    pickle.dump(timestamps, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q git+https://github.com/tensorflow/docs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.densenet import DenseNet121\n","\n","from tensorflow_docs.vis import embed\n","\n","import imageio"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MAX_SEQ_LENGTH = 5\n","NUM_FEATURES = 1024\n","IMG_SIZE_X = 32\n","IMG_SIZE_Y = 48\n","\n","EPOCHS = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = \"cuda\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tf.config.list_physical_devices(\"GPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import collections\n","words = [d.values() for d in timestamps.values()]\n","words = [word for subwords in words for word in subwords]\n","\n","test = collections.Counter(words)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_feature_extractor():\n","    feature_extractor = DenseNet121(\n","        weights=\"imagenet\",\n","        include_top=False,\n","        pooling=\"avg\",\n","        input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3),\n","    )\n","    preprocess_input = keras.applications.densenet.preprocess_input\n","\n","    inputs = keras.Input((IMG_SIZE_X, IMG_SIZE_Y, 3))\n","    preprocessed = preprocess_input(inputs)\n","\n","    outputs = feature_extractor(preprocessed)\n","    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n","\n","\n","feature_extractor = build_feature_extractor()\n","\n","\n","# Label preprocessing with StringLookup.\n","label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(pd.Series(words)), mask_token=None\n",")\n","print(label_processor.get_vocabulary())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prepare_all_videos(timestamps, frames):\n","    num_samples = sum([len(file_frames) for _, file_frames in frames.items()])\n","    labels = pd.Series(words)\n","    labels = label_processor(labels).numpy()[..., None]\n","\n","    # `frame_features` are what we will feed to our sequence model.\n","    frame_features = np.zeros(\n","        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","    )\n","\n","    # For each video.\n","    #for start, end in enumerate(optical_flow_outputs):\n","    idx=0\n","    for file, file_frames in tqdm(frames.items()):\n","        for time, ind_frames in file_frames.items():\n","            ind_frames = np.array(ind_frames)\n","            \n","            # print(ind_frames)\n","            # Pad shorter videos.\n","            if len(ind_frames) < MAX_SEQ_LENGTH:\n","                diff = MAX_SEQ_LENGTH - len(ind_frames)\n","                padding = np.zeros((diff, IMG_SIZE_X, IMG_SIZE_Y, 3))\n","                try:\n","                    ind_frames = np.concatenate((ind_frames, padding))\n","                except:\n","                    continue\n","            \n","            \n","            ind_frames = ind_frames[None, ...]\n","\n","            # Initialize placeholder to store the features of the current video.\n","            temp_frame_features = np.zeros(\n","                shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","            )\n","\n","            # Extract features from the frames of the current video.\n","            for i, batch in enumerate(ind_frames):\n","                video_length = batch.shape[0]\n","                length = min(MAX_SEQ_LENGTH, video_length)\n","                for j in range(length):\n","                    if np.mean(batch[j, :]) > 0.0:\n","                        temp_frame_features[i, j, :] = feature_extractor.predict(\n","                            batch[None, j, :], verbose=0\n","                        )\n","\n","                    else:\n","                        temp_frame_features[i, j, :] = 0.0\n","\n","            frame_features[idx,] = temp_frame_features.squeeze()\n","            idx+=1\n","\n","    return frame_features, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["frame_features, labels = prepare_all_videos(timestamps, frames)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["frame_features.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=output_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.output_dim = output_dim\n","\n","    def build(self, input_shape):\n","        self.position_embeddings.build(input_shape)\n","\n","    def call(self, inputs):\n","        # The inputs are of shape: `(batch_size, frames, num_features)`\n","        inputs = keras.ops.cast(inputs, self.compute_dtype)\n","        length = keras.ops.shape(inputs)[1]\n","        positions = keras.ops.arange(start=0, stop=length, step=1)\n","        embedded_positions = self.position_embeddings(positions)\n","        return inputs + embedded_positions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(dense_dim, activation=keras.activations.gelu),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","\n","    def call(self, inputs, mask=None):\n","        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_compiled_model(shape):\n","    sequence_length = MAX_SEQ_LENGTH\n","    embed_dim = NUM_FEATURES\n","    dense_dim = 4\n","    num_heads = 1\n","    classes = len(label_processor.get_vocabulary())\n","\n","    inputs = keras.Input(shape=shape)\n","    x = PositionalEmbedding(\n","        sequence_length, embed_dim, name=\"frame_position_embedding\"\n","    )(inputs)\n","    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n","    model = keras.Model(inputs, outputs)\n","\n","    model.compile(\n","        optimizer=\"adam\",\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def run_experiment(train_data, train_labels):\n","    filepath = \"/tmp/video_classifier.weights.h5\"\n","    checkpoint = keras.callbacks.ModelCheckpoint(\n","        filepath, save_weights_only=True, save_best_only=True, verbose=1\n","    )\n","\n","    model = get_compiled_model(train_data.shape[1:])\n","    history = model.fit(\n","        train_data,\n","        train_labels,\n","        validation_split=0.15,\n","        epochs=50,\n","        callbacks=[checkpoint],\n","    )\n","\n","    model.load_weights(filepath)\n","    _, accuracy = model.evaluate(test_data, test_labels)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trained_model = run_experiment(frame_features, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trained_model.save_weights('model1000')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4511178,"sourceId":7722520,"sourceType":"datasetVersion"},{"datasetId":4534573,"sourceId":7755036,"sourceType":"datasetVersion"},{"datasetId":4538515,"sourceId":7760426,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
